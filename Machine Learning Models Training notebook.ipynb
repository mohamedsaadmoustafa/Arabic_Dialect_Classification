{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Let's start with importing necessary libraries","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nimport json\nimport tensorflow as tf\nimport unicodedata\nimport re\nimport os\n# visualization packages\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud, ImageColorGenerator\n# sickit learning \nfrom sklearn.decomposition import PCA, TruncatedSVD\nfrom sklearn.ensemble import ExtraTreesClassifier, GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier, VotingClassifier, BaggingClassifier\n#from sklearn.feature_selection import SelectKBest, chi2, SelectFromModel\nfrom sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\n#from sklearn.manifold import TSNE\nfrom sklearn.metrics import precision_score, classification_report, confusion_matrix\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV, ShuffleSplit, RepeatedStratifiedKFold, KFold, cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB, GaussianNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVC, SVC\n# settings\n#sns.color_palette(\"rocket_r\", as_cmap=True)\ncmap = sns.diverging_palette(0, 230, 90, 60, as_cmap=True)\nnp.random.seed(42)\n# ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-13T15:15:43.178332Z","iopub.execute_input":"2022-03-13T15:15:43.179454Z","iopub.status.idle":"2022-03-13T15:15:50.400636Z","shell.execute_reply.started":"2022-03-13T15:15:43.179310Z","shell.execute_reply":"2022-03-13T15:15:50.399609Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/alldialectdataset/out.csv\", encoding=\"utf-8\", lineterminator='\\n')\ndf.drop(columns=[\"id\"], inplace=True)\ndf.columns = ['dialect', 'tweets']\ndf.dropna(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:15:50.402429Z","iopub.execute_input":"2022-03-13T15:15:50.402701Z","iopub.status.idle":"2022-03-13T15:15:54.600862Z","shell.execute_reply.started":"2022-03-13T15:15:50.402670Z","shell.execute_reply":"2022-03-13T15:15:54.600072Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## `Clean Text` \nNext step to try several preprocessing methods **one at a time** to clean our tweets like:-\n\n        * Select arabic characters only from text\n        * Remove username \"@handle\" from text\n        * Remove URL from text\n        * Remove punctuation, emoji and smileys from text\n        * Remove \\n, \\t ,,, etc from text\n        * Remove Diacritization from text\n        * Remove Arabic Stop Words from text\n        \n> Only  removing Diacritization and Escape Codes makes a slightly improvment in score.","metadata":{}},{"cell_type":"code","source":"from nltk.corpus import stopwords\nnltk_stopwords = stopwords.words('arabic')\nnltk_stopwords[:10]","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:15:54.602377Z","iopub.execute_input":"2022-03-13T15:15:54.602726Z","iopub.status.idle":"2022-03-13T15:15:55.095253Z","shell.execute_reply.started":"2022-03-13T15:15:54.602669Z","shell.execute_reply":"2022-03-13T15:15:55.094305Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def remove_stop_words(text):\n    words = [word for word in text.split() if word not in nltk_stopwords]\n    return \" \".join(words)    ","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:15:55.097892Z","iopub.execute_input":"2022-03-13T15:15:55.098438Z","iopub.status.idle":"2022-03-13T15:15:55.103991Z","shell.execute_reply.started":"2022-03-13T15:15:55.098389Z","shell.execute_reply":"2022-03-13T15:15:55.103076Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"> Preprocessing Pipeline","metadata":{}},{"cell_type":"code","source":"def clean_text(text):\n    ##text = ' '.join(re.findall(r'[\\u0600-\\u06FF]+', text)) # Select arabic characters only from text\n    ###text = re.sub(r'(@.*?)[\\s]', ' ', text) # Remove username \"@handle\"\n    ##text = re.compile(r'https?://\\S+|www\\.\\S+').sub(r'', text) # Remove username \"@handle\"\n    ##text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation, emoji and smileys\n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove Escape Codes\n    text = re.sub(re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]'),\"\", text) # Remove Diacritizations\n    #text = remove_stop_words(text)\n    text = text.strip() \n    return text\n\ndf['clean_tweets'] = df.tweets.apply(lambda t: clean_text(t))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:15:55.105400Z","iopub.execute_input":"2022-03-13T15:15:55.105649Z","iopub.status.idle":"2022-03-13T15:16:03.341542Z","shell.execute_reply.started":"2022-03-13T15:15:55.105620Z","shell.execute_reply":"2022-03-13T15:16:03.340646Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder \nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndf['dialect_encode'] = le.fit_transform( df['dialect'] ).astype(np.int8)\ntarget_names = le.inverse_transform(np.arange(18))\ntarget_names","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.343136Z","iopub.execute_input":"2022-03-13T15:16:03.343596Z","iopub.status.idle":"2022-03-13T15:16:03.503093Z","shell.execute_reply.started":"2022-03-13T15:16:03.343545Z","shell.execute_reply":"2022-03-13T15:16:03.501970Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1200/1*3-KkZ0hlRZxjMn7Z6uXDGg.png)","metadata":{}},{"cell_type":"code","source":"#X = df.tweets#clean_tweets#.values\nX = df.clean_tweets.values\ny = df.dialect_encode.values\ny = np.array(y).reshape((-1,1)).ravel()","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.505253Z","iopub.execute_input":"2022-03-13T15:16:03.505614Z","iopub.status.idle":"2022-03-13T15:16:03.512057Z","shell.execute_reply.started":"2022-03-13T15:16:03.505567Z","shell.execute_reply":"2022-03-13T15:16:03.511370Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# The train val split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.7, shuffle=True, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.513306Z","iopub.execute_input":"2022-03-13T15:16:03.513595Z","iopub.status.idle":"2022-03-13T15:16:03.662479Z","shell.execute_reply.started":"2022-03-13T15:16:03.513561Z","shell.execute_reply":"2022-03-13T15:16:03.661579Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"n_estimators = 10","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.663961Z","iopub.execute_input":"2022-03-13T15:16:03.664219Z","iopub.status.idle":"2022-03-13T15:16:03.669366Z","shell.execute_reply.started":"2022-03-13T15:16:03.664191Z","shell.execute_reply":"2022-03-13T15:16:03.668361Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def text_pipeline(clf):\n    return Pipeline([\n        ('vect', CountVectorizer()), # , tokenizer=clean_text\n        ('tfidf', TfidfTransformer()),\n        ('clf', OneVsRestClassifier(clf, n_jobs=-1))\n    ])","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.672593Z","iopub.execute_input":"2022-03-13T15:16:03.672881Z","iopub.status.idle":"2022-03-13T15:16:03.682690Z","shell.execute_reply.started":"2022-03-13T15:16:03.672849Z","shell.execute_reply":"2022-03-13T15:16:03.681852Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"clfs = {\n    'LinearSVC': LinearSVC(),\n    'LogisticRegression': LogisticRegression(C=5, solver='newton-cg', max_iter=1000, multi_class='ovr'),\n    #'SGDClassifier': SGDClassifier(loss='epsilon_insensitive', penalty='l2',alpha=0.0001, random_state=42), \n}","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.684119Z","iopub.execute_input":"2022-03-13T15:16:03.684536Z","iopub.status.idle":"2022-03-13T15:16:03.697226Z","shell.execute_reply.started":"2022-03-13T15:16:03.684493Z","shell.execute_reply":"2022-03-13T15:16:03.696244Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"results = {}\nfor classifier_name, clf in clfs.items(): \n    text_clf  = text_pipeline(clf)\n    text_clf.fit(X_train, y_train)\n    predicted = text_clf.predict(X_val)\n    # model accuracy: the total ratio of tp/(tp + fp)\n    score = precision_score(predicted, y_val, average='micro') #np.mean(predicted == y_val)\n    #print(classifier_name, score)\n    \n    results[classifier_name] = {\n        \"score\" : score,\n        \"confusion_matrix\": confusion_matrix(y_val, predicted),\n        \"classification_report\": classification_report(\n            predicted, \n            y_val,\n            target_names = target_names, \n            digits=2,\n            output_dict=True\n        ),\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:16:03.698784Z","iopub.execute_input":"2022-03-13T15:16:03.699079Z","iopub.status.idle":"2022-03-13T15:17:48.955790Z","shell.execute_reply.started":"2022-03-13T15:16:03.699033Z","shell.execute_reply":"2022-03-13T15:17:48.954479Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### Scores\n`LinearSVC`\n> 0.658\n\n`Logistic Regression`\n> 0.636\n\n`SGD Classifier`\n> 0.617","metadata":{}},{"cell_type":"code","source":"for classifier_name, clf in clfs.items(): \n    print(classifier_name, round(results[classifier_name]['score'], 3))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:17:48.957364Z","iopub.execute_input":"2022-03-13T15:17:48.957731Z","iopub.status.idle":"2022-03-13T15:17:48.964520Z","shell.execute_reply.started":"2022-03-13T15:17:48.957701Z","shell.execute_reply":"2022-03-13T15:17:48.963634Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"`Confusion Matrix`","metadata":{}},{"cell_type":"code","source":"def ConfusionMatrix(cm):\n    #cm = confusion_matrix(y_val, predicted)\n    df_cm = pd.DataFrame(cm, target_names, target_names)\n\n    plt.figure(figsize = (20, 18))\n    sns.set(font_scale=1.4) # for label size\n    sns.heatmap(\n        df_cm,\n        fmt=\".1f\", annot=True, annot_kws={'size': 12}, cmap=cmap,\n        linewidths=3,\n    );\n    return None\n    \ndisplay([\n    ConfusionMatrix(results['LinearSVC']['confusion_matrix']), \n    ConfusionMatrix(results['LogisticRegression']['confusion_matrix']),\n    #ConfusionMatrix(results['SGDClassifier']['confusion_matrix'])\n])","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:17:48.965826Z","iopub.execute_input":"2022-03-13T15:17:48.966393Z","iopub.status.idle":"2022-03-13T15:17:53.447050Z","shell.execute_reply.started":"2022-03-13T15:17:48.966361Z","shell.execute_reply":"2022-03-13T15:17:53.446179Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Notices from Confusion Matrix\nLet's focus in high misclassification ratio happens for each dialect:- \n\n    - `AE` :  SA, KW, BH\n    - `BH` :  AE, KW, OM, SA, QA\n    - `DZ` :  MA, TN, LY\n    - `EG` :  LY, PL, SD\n    - `IQ` :  KW, BH\n    - `JO` :  PL, LB, SY\n    - `KW` :  BH, AE, QA, SA\n    - `LB` :  PL, SY\n    - `LY` :  EG, KW, PL, TN\n    - `MA` :  DZ, LY\n    - `OM` :  AE, BH, KW, QA, SA\n    - `PL` :  JO, EG, LB, LY, SY\n    - `QA` :  SA, KW, AE, BH\n    - `SA` :  QA`, KW, BH, AE\n    - `SD` :  EG, LY, PL\n    - `SY` :  LB, PL\n    - `TN` :  LY, DZ\n    - `YE` :  SA\n    \n    \n    \n`Most of misclassifications happens for each dialect with dialects for share border countries. So we can break a classifier into three to five classifiers. each classifier for a group of share border countries like:-`\n\n    - ['QA', 'SA', 'AE', 'KW', 'OM', 'YE','BH']\n    - ['LY', 'SY', 'JO', 'PL', 'IQ']\n    - ['EG', 'LY', 'SD']\n    - ['TN', 'MA', 'DZ']","metadata":{}},{"cell_type":"markdown","source":"By breaking down accuracy scores to individual classes. If a model has higher accuracy scores for some classes than another model and vice versa we can use `Voting Classifier` to get a better overall accuracy. ","metadata":{}},{"cell_type":"code","source":"def breakdown_scores(matrix, pres):\n    all_scores = pd.DataFrame()\n    for i, matrix in enumerate(matrix):\n        matrix = matrix.diagonal() / matrix.sum(axis=1)\n        all_scores = pd.concat([\n            all_scores, \n            pd.DataFrame({'Dialect': target_names, 'scores': matrix})\n        ], axis=1)#.add_prefix(pres[i])\n    return all_scores#.sort_values(by=['scores'], ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:17:53.448595Z","iopub.execute_input":"2022-03-13T15:17:53.448821Z","iopub.status.idle":"2022-03-13T15:17:53.455250Z","shell.execute_reply.started":"2022-03-13T15:17:53.448793Z","shell.execute_reply":"2022-03-13T15:17:53.454250Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"breakdown_scores(\n    [\n        results['LinearSVC']['confusion_matrix'],\n        results['LogisticRegression']['confusion_matrix'],\n        #results['SGDClassifier']['confusion_matrix']\n    ],\n    ['svc_', 'log_'] #, 'sgd_'\n    \n)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:17:53.456926Z","iopub.execute_input":"2022-03-13T15:17:53.457662Z","iopub.status.idle":"2022-03-13T15:17:53.488679Z","shell.execute_reply.started":"2022-03-13T15:17:53.457623Z","shell.execute_reply":"2022-03-13T15:17:53.488057Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"`Precision-Recall` is a useful measure of success of prediction when the classes are very imbalanced. \nIn information retrieval, `precision` is a measure of result relevancy, while `recall` is a measure of how many truly relevant results are returned.","metadata":{}},{"cell_type":"code","source":"def Report(rp):\n    report = pd.DataFrame(rp).T\n    report['support'] = report.support.apply(int)\n    return report\n    \npd.concat([\n    Report(results['LinearSVC']['classification_report']).add_prefix('svc_'),\n    Report(results['LogisticRegression']['classification_report']).add_prefix('log_'), \n    #Report(results['SGDClassifier']['classification_report']).add_prefix('sgd_'),\n], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:17:53.489867Z","iopub.execute_input":"2022-03-13T15:17:53.490233Z","iopub.status.idle":"2022-03-13T15:17:53.519931Z","shell.execute_reply.started":"2022-03-13T15:17:53.490201Z","shell.execute_reply":"2022-03-13T15:17:53.518919Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1200/1*3-KkZ0hlRZxjMn7Z6uXDGg.png)","metadata":{}},{"cell_type":"markdown","source":"# OverSampling\nBy viewing the percentage of each dialect in the dataset is shows that it's imbalanced.\n    - EG dialect has  balance a datase 12.6%\n    - AE dialect has  balance a datase 5.74%\n    - TN dialect has  balance a datase 12.5%\n\nTrying to improve the performance of ML models we can use `Oversampling`.\n\n`Oversampling` is a technique which increases the number of samples of the smallest class up to the size of the biggest class. This is done by generating synthetic samples.","metadata":{}},{"cell_type":"code","source":"#from imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler\n\nX = TfidfVectorizer().fit_transform(df['clean_tweets'])\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.7, shuffle=True, random_state = 42)\nX_train, y_train = RandomOverSampler(random_state=42).fit_resample(X_train, y_train)\n\nOverSampler_results = {}\nfor classifier_name, text_clf in clfs.items(): \n    text_clf.fit(X_train, y_train)\n    predicted = text_clf.predict(X_val)\n    score = precision_score(predicted, y_val, average='micro')\n    OverSampler_results[classifier_name] = {\n        \"score\" : score,\n        \"confusion_matrix\": confusion_matrix(y_val, predicted),\n        \"classification_report\": classification_report(\n            predicted, \n            y_val,\n            target_names = target_names, \n            digits=2,\n            output_dict=True\n        ),\n    }","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:17:53.521696Z","iopub.execute_input":"2022-03-13T15:17:53.522669Z","iopub.status.idle":"2022-03-13T15:28:01.282286Z","shell.execute_reply.started":"2022-03-13T15:17:53.522603Z","shell.execute_reply":"2022-03-13T15:28:01.281028Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"### Scores after using OverSampling\n`LinearSVC`\n> 0.653\n\n`logisticregresion`\n> 0.641\n\n`SGD Classifier`\n> 0.617","metadata":{}},{"cell_type":"code","source":"for classifier_name, clf in clfs.items(): \n    print(classifier_name, round(OverSampler_results[classifier_name]['score'], 3))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:28:01.283828Z","iopub.execute_input":"2022-03-13T15:28:01.284129Z","iopub.status.idle":"2022-03-13T15:28:01.290739Z","shell.execute_reply.started":"2022-03-13T15:28:01.284094Z","shell.execute_reply":"2022-03-13T15:28:01.289869Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1200/1*3-KkZ0hlRZxjMn7Z6uXDGg.png)","metadata":{}},{"cell_type":"markdown","source":"### Last Model\n\nUnlike linearsvm, LogisticRegression has a pridect_prop function and since their accuracy scores are close, we choose\nLogisticRegression model with multi_class parameter to 'ovr' which use One Vs Rest technique.\n\nLet's starting with using TfidfVectorizer followed by oversampling method then training chosen model.","metadata":{}},{"cell_type":"code","source":"model = LogisticRegression(C=5, solver='newton-cg', max_iter=1000, multi_class='ovr')\nmodel.fit(X_train, y_train)\npredicted = text_clf.predict(X_val)\nprecision_score(predicted, y_val, average='micro')","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:28:01.292163Z","iopub.execute_input":"2022-03-13T15:28:01.292420Z","iopub.status.idle":"2022-03-13T15:36:50.611404Z","shell.execute_reply.started":"2022-03-13T15:28:01.292389Z","shell.execute_reply":"2022-03-13T15:36:50.610187Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"breakdown_scores([confusion_matrix(y_val, predicted)], pres=['']).sort_values(by=['scores'], ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:36:50.612925Z","iopub.execute_input":"2022-03-13T15:36:50.613233Z","iopub.status.idle":"2022-03-13T15:36:50.704456Z","shell.execute_reply.started":"2022-03-13T15:36:50.613198Z","shell.execute_reply":"2022-03-13T15:36:50.703477Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### OverSampling makes an improvment to dailects with smaller amount texts like `YE`","metadata":{}},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/1200/1*3-KkZ0hlRZxjMn7Z6uXDGg.png)","metadata":{}},{"cell_type":"markdown","source":"# `Save Model`\nUsing `pickle` package to save our trained model for local deployment.","metadata":{}},{"cell_type":"code","source":"import pickle\n\n# save the model to disk\nfilename = 'model.sav'\npickle.dump(model, open(filename, 'wb'))","metadata":{"execution":{"iopub.status.busy":"2022-03-13T15:36:50.706372Z","iopub.execute_input":"2022-03-13T15:36:50.706713Z","iopub.status.idle":"2022-03-13T15:36:50.963332Z","shell.execute_reply.started":"2022-03-13T15:36:50.706673Z","shell.execute_reply":"2022-03-13T15:36:50.962411Z"},"trusted":true},"execution_count":22,"outputs":[]}]}