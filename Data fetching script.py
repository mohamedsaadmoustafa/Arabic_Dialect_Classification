{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport requests\nimport json\nimport os\n\n# Import dataset with text ids.\ndf = pd.read_csv(\"../input/dialect-datasetcsv/dialect_dataset.csv\")\n# create a new column to store feched text in\ndf['tweets'] = np.nan\n# change 'id' column type to string.\ndf.id = df.id.astype(str)\n\n# api-endpoint\nURL = 'https://recruitment.aimtechnologies.co/ai-tasks'\nstart_sample, end_sample = 0, 0\nnum_samples = 1000\n# Divide dataset length by maximum number of texts per request\n#  to calculate the number of requests\nquotient = len(df) // num_samples  # 458\nremainder = len(df) % num_samples  # 197\n\n# Run to get 1000 text and save them into our dataframe and save it \ndef get_data(start_sample, num_samples):\n    # calcualate end point of a request\n    end_sample = start_sample + num_samples\n    # get sample ids for POST\n    sample = df.id[start_sample:end_sample].tolist()\n    #print(sample[0])\n    # sava sample as json\n    with open('example.json', 'w') as txtfile:\n        json.dump(sample, txtfile)\n    # defining a params dict for the parameters to be sent to the API\n    example = open('example.json', 'rb').read()\n    # sending get request and saving the response as response object\n    r = requests.post(url = URL, data = example)\n    # extracting data in json format\n    data = r.json()\n    return data\n\n# save requests texts in our dataset\ndef compine_data(df, post_data):\n    d = pd.DataFrame.from_dict(post_data, orient='index')\n    d.reset_index(inplace = True)\n    d.columns = ['id', 'tweets']\n    df = df.set_index('id').combine_first(d.set_index('id')).reset_index() # combine \n    return df\n\n# make 458 'quotient' request -> quotient * num_samples = 458 * 1000\nfor i in range(quotient):\n    start_sample = num_samples * i\n    print(start_sample)\n    #get 1000 sample and save it\n    post_data = get_data(start_sample, num_samples)\n    df = compine_data(df, post_data)\n\n# get the rest of data in one request for 197 ids\nif remainder != 0: \n    print('start remainder')\n    start_sample = quotient * 1000\n    #pass#print(\"get 1000 sample and save it\")\n    post_data = get_data(start_sample, remainder+1)\n    # save to dataset\n    df = compine_data(df, post_data)\n    print(\"save last\")\n    \n# SAVE OUR COMPLETE DF\nfile_name = 'out.csv'\ndf.to_csv(file_name, index=False, encoding=\"utf-8\")","metadata":{"_uuid":"c0ad352c-a167-499f-a69a-2d444360cd51","_cell_guid":"90dad43c-c361-4c31-b3a2-b19ceccbd225","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}